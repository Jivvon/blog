---
name: 정지원
avatar: /static/images/avatar.png
occupation: DevOps Engineer
company: Channel.io
email: jwjeong127@gmail.com
linkedin: https://www.linkedin.com/in/jwjeong
github: https://github.com/Jivvon
---

## 소개

**문제를 해결하는 데에 즐거움을 느끼는** 데브옵스 엔지니어입니다.

**상황에 맞는 최선의 선택**을 하기 위해 고민합니다.<br />
프로젝트에 할당된 기간, 확장성, 지속 가능성, 비용 효율성을 고려하여 아키텍처를 설계하고 기술을 활용합니다.

기술이 가진 **책임**과 **영향력**을 이해하고, 조심스럽지만 과감하게 행동합니다.<br />
이를 위해 단순히 기술을 사용하는 것을 넘어, 근본적인 원리를 이해하기 위해 노력합니다.

문제를 분석하고, 원인을 파악하여 해결하는 과정에서 즐거움을 느낍니다.<br />
특히, 다른 직무의 동료와 함께 다양한 관점으로 문제를 바라보고 토론하는 것은 언제나 재미있습니다.<br />
&nbsp;&nbsp; → [Kubernetes 환경에서 WebRTC 서비스의 묵음 현상 분석기](#블로깅)

일을 찾아서 움직이는 성향 덕분에, 자연스럽게 일의 **우선순위를 수시로 조정**하며 진행합니다.<br />
주어진 업무 외에도 팀에 도움이 되는 방향이 있다면 먼저 제안하고 움직이며, 전체적인 효율과 팀의 방향성을 함께 고려하여 기술적인 의사결정을 내립니다.

## 커리어

### Channel Corporation - DevOps Engineer [2022.05 ~ ]

입사 직후 Kubernetes 도입 및 서비스 운영 환경 설계를 주도하였고, 기존 ECS 기반의 인메모리 DB 및 메인 서버를 포함한 전체 시스템을 EKS로 성공적으로 마이그레이션하였습니다. <br />
Meet팀 소속으로 채널톡 전화 서비스 관련 DevOps 업무를 수행하며 WebRTC 서버 구축, 아키텍처 설계 참여, STT 비용 최적화 및 속도 개선을 이루었습니다.<br />
Terraform CI에서 권한 확인을 위한 어플리케이션 개발, 오퍼레이터 패턴으로 개발된 내부 배포 시스템의 기능 추가 등 개발 업무에도 참여하였습니다.<br />
현재는 글로벌 인프라 확장 및 멀티 클러스터 환경을 고려한 프로비저닝 자동화와 아키텍처 설계를 진행하고 있습니다.

### SI Analytics - DevOps Engineer [2021.03 ~ 2022.02]

온프레미스 환경에서 총 21대의 물리 서버(CPU + GPU)와 44대의 VM으로 구성된 5개의 Kubernetes 클러스터를 구축 및 운영하였습니다.<br />
각 클러스터는 Control Plane 노드 3대를 구성하고 HAProxy를 활용해 고가용성을 확보하였으며, 
etcd 및 쿠버네티스 리소스에 대한 주기적인 백업과 복원이 가능한 환경을 구성하였습니다.<br />
또한, 클러스터 전반에 적용될 정책을 설계하고, Admission Controller를 활용하여 보안성과 일관성을 강화하였습니다.<br />
Grafana, Loki, Prometheus, Alertmanager를 연동한 모니터링 시스템을 구축하였으며,
DCGM Exporter에 필요한 메트릭을 추가하고 직접 바이너리를 빌드하여 GPU 관련 정보를 연구자들에게 제공하였습니다.


## 역량 (3개만 적기)

(예시) 1) 기존 시스템에 대한 퍼포먼스 및 오류 개선
(예시) 어플리케이션 기획 및 개발 / 개선

<details>
<summary>** 소제목 **</summary>

## 내용 ~~

</details>

-----------------------------------------------------------------------------------------------------------------------


### 아키텍처 고심한 썰
- 전화연동
    - turn 서버를 사용하지 않고 public 으로 그대로 노출하게 된 썰
        요청이 일정 기준치 이상을 넘기면 turn 서버를 도입하여 ~~을 ~~할 예정
        EIP pool로 사용하고 있기 때문에 동시성 문제를 해결해야 함. 서비스 특성상 당장 빠르게 고민해야 할 문제가 아니여서 백로그 상태
    - whisper spot으로 돌린 썰
        실시간성을 보장하지 않아도 되는 서비스 특성 상 queue에 넣고 모두 spot으로 돌림
        크기가 큰 모델 빠르게 올리기
            spot을 사용하기 때문에 인스턴스 kubelet의 이미지 캐싱을 활용하기에는 어려웠음
            볼륨 스냅샷을 활용해서 인스턴스 프로비저닝시 마운트하는 방법 (disk iops or network bandwidth)
            모델이 포함된 AMI 빌드해서 사용
        동일한 기능을 제공하는 Saas보다 훨씬 적은 비용으로 운영 중
    - WebRTC 녹음 서버에서 내부적으로 리소스를 관리하여 스케일링 정책을 정하기 어려웠음


- ECS -> EKS 마이그레이션 무중단
    - ECS에서는 CloudMap과 LB를 혼용해서 사용하다가, EKS로 옮길 땐 LB로 모두 옮긴 후 TargetGroup의 weight를 조절하며 마이그레이션을 수행함
    - DynamoDB Streams로 업데이트하던 인메모리 데이터베이스를 중단 없이 마이그레이션하였습니다
        기존의 무거웠던 AWS Lambda의 역할을 나누었음
        특정 비즈니스 모델을 기준으로 DB를 나누었음
        아래의 순서대로 함
        1. Cloud Map을 사용하던걸 ALB로 옮김
        2. EKS에 인스턴스를 준비하고 DynamoDB Streams를 ECS와 EKS 동시에 흘러들어가도록 함
        3. url path와 Header를 활용하여 내부 특정 채널만을 대상으로 EKS로 마이그레이션된 DB에 대해 테스트함
        4. 모니터링하며 ALB listener rule의 weight를 조절하여 1주에 걸쳐 마이그레이션을 완료함
        DB 컨테이너당 하나의 타입만 지원하는 특성을 고려하여, topologySpreadConstraints로 서로 다른 타입의 컨테이너는 다른 인스턴스에 스케줄링되도록 하여 가용성을 확보함
    

- terraform module to s3 and versioning & seperate states
    - 문제점
        - 환경별로 분리된 state가 너무 커서 전체 plan 시간이 오래걸렸고, 그러다보니 target을 지정해서 작업하게 됨. 작업자가 여럿이고 싱크를 놓치는 경우가 쌓이며 생산성이 저하됨
        - Region별로 state가 분리되어 있었음
        - 모든 환경에서 모듈을 공통으로 사용하기 때문에, 모듈 수정에 대한 부담이 굉장히 컸음
        - 팀원들은 환경별 권한이 다르기 때문에 production 환경에 대한 작업인 경우 상급자가 보틀넥이 되었음
        - CI/CD 파이프라인의 부재로 동시에 여러명이 작업하기 불편했음
        - 중복 코드가 너무 많았음
    - 해결
        - Terragrunt를 도입하여 state를 잘게 나누고 병렬로 실행할 수 있도록 수정함
        - Terragrunt 도입과 Git Repository 구조 변경으로 Account, Region, Stage 등 특정 scope 단위로 코드를 재사용할 수 있게 됨
        - 모듈을 버저닝하여 AWS S3에서 관리하도록 함
        - CI/CD 도구로써 Atlantis를 도입함. atlantis와 terragrunt가 포함된 이미지를 직접 빌드하여 사용함
        - atlantis에서 권한 확인을 위한 GoLang 프로그램을 개발함. Okta에서 관리하는 기준과 Github Team에서 설정된 기준이 달라서 개발했어야 했음


### 최적화 썰
- 모니터링 시스템
  - recording rule
  - cardinality, tsdb status
- general chart
- multicluster
  - chart 


### 개발 썰
- DCGM Exporter 
- atlantis-permission-checker


### 도구 검토
- 모니터링 시스템
    Loki vs Elasticsearch
- Terraform CI
    Atlantis vs Github Action
- Terragrunt
    여러 개의 state로 쪼개기
- MultiCluster
    ClusterAPI vs Terraform CI


## 블로깅

### [Kubernetes 환경에서 WebRTC 서비스의 묵음 현상 분석기](https://channel.io/ko/blog/articles/kubernetes-webrtc-07b0d3b3)

Kubernetes 환경의 Meet 서비스 스케일링 과정에서 발생한 WebRTC 묵음 현상에 대해 원인을 분석하고 해결해나가는 과정을 채널톡 기술블로그에 작성하였습니다

## 학력

### 충남대학교 - 컴퓨터공학과 [2015.02 ~ 2022.02]

학점 3.76/4.5 (전공 3.86/4.5)





---

**보안**

- 사용자 관리
    - AWS Config를 활용하여 Access Key와 Secret Key에 대한 key rotate rule 설정
    - 서비스별 특징에 따라 접근 가능한 범위를 세분화하여 IP 제한 및 MFA 설정을 강제하는 Policy 적용
    - Okta를 SSOT(Single Source of Truth)로 하여 Grafana, ArgoCD, Argo Workflows 등 OIDC 적용
- 내부 관리 페이지에서 특정 IP에 대한 접근을 차단하기 위해 AWS WAF를 래핑한 API 서버 개발

<br/>

**비용 효율화**

- AWS 리소스 정리
    - Terraform aws provider에 default 태그를 추가하여 리소스 추적
    - Terraform으로 관리되지 않는 리소스의 경우 AWS Config를 활용하여 자동으로 정리되도록 설정
- Karpenter Spot 인스턴스

<br/>

**채널톡 [전화 연동](https://channel.io/ko/meet/call) 인프라 개선 및 관리 [2024.04 ~ 2025.03]**

- WebRTC 서버 업그레이드를 위한 설계
    - 비즈니스 영향도를 고려한 카나리 배포 전략 채택
    - 애플리케이션 수준에서 서로 다른 버전의 WebRTC 서버와 통신할 수 있는 구조 제안
    - 무중단 배포와 원활한 롤백 전략을 고려
- MSA 구조로 전환하기 위한 설계 (2025.03)
    - 외부(고객사의 컴퓨터, 고객사의 물리 전화, 엔드 유저의 통신사)와 통신하는 서버들을 고려한 토폴로지 설계
    - 확장성과 가용성을 고려하여 RTP 프로토콜 중계 서버 제안

<br/>

**채널톡 [전화 연동](https://channel.io/ko/meet/call) 인프라 구성 [2023.02 ~ 2023.12]**

- Peer와 직접 통신하는 서버의 경우 hostNetwork를 사용하여 노드의 특정 UDP 대역을 사용하도록 설정
- 통신사와 고정된 Port로 통신하기 위해 SNAT를 비활성화하는 CNI Plugin 설정 적용
- Media 서버의 요청 타입 및 내부 알고리즘을 고려하여 로드 밸런싱 & 오토 스케일링 되도록 최적화
- 전화 연동 관련 인프라 CI/CD 파이프라인 구성, Helm Chart 작성 및 배포

_Tech Skills. `EKS` `WebRTC`_

<br/>

**Terraform 프로젝트 및 개발 환경 개선 [2024.07 ~ 2024.12]**
  - 멀티 리전, 멀티 클러스터를 고려하여 팀원 전체가 공동 작업 가능한 프로젝트 형태로 개선
  - Terragrunt를 도입하여 동일한 어카운트나 리전 등 특정 범위 내에서 동일한 값을 재사용 하도록 개선
  - Atlantis를 사용하여 CI & CD를 자동화하고, state를 세부적으로 나누어 여러 작업자가 다른 환경에 동시에 작업 가능하도록 개선
  - 작업자들의 권한을 세부적으로 관리하기 위한 tool을 개발하여 적용
  - 모든 의사결정 사항을 문서화하여 팀 내 공유

**EKS 모니터링 시스템 구축 [2023.06 ~ 2023.07]**

- 각 Exporter와 Prometheus, Grafana를 활용하여 메트릭 수집 및 시각화
- Thanos를 활용하여 가용성 확보 및 메트릭 장기 저장
- Promtail, Loki, Grafana를 활용하여 로그 수집 및 시각화
- 특정 로그 발생시 채널톡으로 알람을 보내주는 Webhook 서버 및 AWS Lambda 개발

_Tech Skills. `Kubernetes`  `Helm`  `Prometheus`  `Loki`  `Grafana` `Go`_

<br/>

**Terraform 리팩토링 및 모듈화 [2022.10 ~ 2023.02]**

- 기본적으로 Terraform AWS 모듈을 사용하고, 상황에 따라 수정하거나 새로 개발하여 사용
- 동일한 형태가 반복되는 경우에는 yaml에서 가져오도록 수정
- 패턴화된 Security Group Rule을 그룹화하여 가독성 및 유지보수성 향상
- 내부 모듈 저장소(S3)를 사용할 예정 (TO-BE)
    - 모듈 변경이 필요할 때, 해당 모듈을 사용하는 다른 state에 영향을 미치지 않게 하기 위해 모듈의 버전 관리가 필요함
    - 현재는 환경별 브랜치를 구분하여 사용 중 → 동일한 작업을 환경별로 반복해야 함
    - 단일 Git 저장소에 모아놓고 모듈의 source에 Github scheme을 사용 → plan, apply시 Git 저장소 전체를 가져오기 때문에 오래 걸림
    - S3에 모듈을 버전별로 올려놓고 terraform 명령시 해당 모듈을 받아오는 툴을 개발하여 사용 → 개발 필요

_Tech Skills. `Terraform`_

<br/>

**EKS 환경 셋업 & ECS → EKS 마이그레이션 환경 구성 [2022.07 ~ 2022.09]**

- 어플리케이션 Helm Chart 작성
- Cluster Autoscaler를 활용하여 Node 오토스케일링, HPA를 활용하여 Pod 오토스케일링 적용
- External DNS를 활용하여 Route53과 CloudMap 설정
- AWS Load Balancer Controller의 TargetGroupBinding을 사용하는 차트 작성 및 ELB와 TG는 Terraform으로 생성
- ArgoCD를 이용하여 GitOps 방식의 CD 구현
- 개발용 서버 인프라를 ECS에서 EKS로 마이그레이션

_Tech Skills. `EKS` `Helm` `Terraform` `ArgoCD` `AWS Route53` `AWS CloudMap`_

<br/>

**CI/CD 파이프라인 빌드 개선 [2022.06 ~ 2022.07]**

- 주요 어플리케이션의 CI 파이프라인에서 Docker buildx를 활용하여 멀티 아키텍처 빌드를 하도록 개선
- 캐싱, Graceful Shutdown, 런타임 이미지 경량화를 고려하여 Dockerfile 개선 및 CI 개선

_Tech Skills. `Docker` `CircleCI`_

---

## SI Analytics - DevOps Engineer [2021.03 ~ 2022.02]

<br/>

**쿠버네티스 클러스터 운영**

온프레미스 환경에서 총 21대의 물리 서버와 44대의 VM으로 구성된 5개의 Kubernetes 클러스터를 관리하였습니다.

- **OPA Gatekeeper를 활용하여 Admission Control 적용**
    - previleged mode나 루트 계정으로 컨테이너를 생성하지 못하도록 제한하는 정책 적용
    - [gatekeeper-library](https://github.com/open-policy-agent/gatekeeper-library)에서 가져와 조건을 수정한 후 RBAC 관련 helm chart에 포함시켜 적용
- **클러스터 접근제어 환경 구축 및 설정 (User Account, RBAC, OPA Gatekeeper)**
    - RBAC를 활용한 Helm chart 작성
        - Rolebinding / ClusterRolebinding : 공통 values에서 그룹별 사용자를 정의하고 각 ClusterRole에서 그룹을 할당하는 방식으로 사용
        - ClusterRole : 기본 권한을 기반으로 필요에 따라 aggregate를 활용하여 권한 추가 가능
- **모델 학습 및 서빙을 위한 환경 구성**
    - 사내 및 IDC에 각각 A100, V100을 포함한 GPU 머신으로 클러스터를 구축하고 모델 학습 및 서빙 파이프라인을 구성하여 연구자들의 연구 환경을 대폭 개선함
    - (AS-IS) 스케줄을 작성하고 연구자들이 돌아가며 GPU 인스턴스에 직접 접속하여 학습 -> (TO-BE) mlflow, minio와 더불어 팀 내에서 자체 개발한 모델 학습 스케줄러를 이용하여 여러 팀원들이 비동기식으로 GPU 자원을 사용함
        - (AS-IS) 스케줄을 협의하는 커뮤니케이션 비용이 상당하였으며, 스케줄 사이의 시간, 할당되었지만 남은 시간 등 GPU를 사용하지 않는 시간이 약 15%~20% 정도 되었음
        - (TO-BE) 모든 연구자들이 비동기식으로 학습을 요청하며, 작은 단위로 나누어진 작업들은 우선순위에 따라 자동으로 스케줄링되어 작업자의 피로도는 감소하고, GPU는 밤낮, 주말 내내 100% 사용률을 유지하였음

_Tech Skills. `Kubernetes`  `Helm`  `ArgoCD`  `Prometheus`  `Loki`  `Grafana` `OPA`_

<br/>

**모니터링 시스템 구축 및 운영 [2021.03 ~ 2022.02]**

- 메트릭, 로그, 알림 흐름
    - 메트릭은 각 Exporter → Prometheus → Grafana 흐름으로 메트릭을 수집 및 저장하여 시각화
    - 로그는 각 노드의 Promtail → Loki → Grafana 흐름으로 로그를 수집 및 저장하여 시각화
    - 알림은 Prometheus → Alertmanager → Prometheus-msteams → MS Teams 흐름으로 알림 발생
- Prometheus Operator를 사용하여 가용성을 높이고 동적으로 설정이 적용되도록 구성
    - 모니터링 대상이나 Alert rule이 변경되면, 이를 보고 있던 Prometheus Operator가 설정 파일을 수정하여 적용
    - Prometheus 서버와 AlertManager를 이중화하여 서비스의 가용성을 높임
- DCGM Exporter에서 수집하는 메트릭의 레이블에 GPU 모델명을 추가하여 사내에 제공하고 공식 레포에 PR 생성 [[링크](https://gitlab.com/nvidia/container-toolkit/gpu-monitoring-tools/-/merge_requests/71)]

_Tech Skills. `Kubernetes`  `Helm`  `Prometheus`  `Loki`  `Grafana` `Go`_

<br/>

**쿠버네티스 환경 백업 및 복원 시스템 구축 [2021.09 ~ 2022.10]**

쿠버네티스 클러스터의 모든 리소스와 주요 서비스를 백업 및 복원하는 시스템을 구축하였습니다.

- Harbor: Database 덤프를 생성하는 스크립트 작성 후 cronjob으로 실행
- ETCD: Etcdctl을 이용하여 스냅샷 생성하는 스크립트 작성 후 cronjob으로 실행
- K8S Resources: velero를 이용하여 주기적으로 네임스페이스별 모든 리소스를 Minio에 백업

_Tech Skills. `Kubernetes`  `Helm`  `Shell`  `ArgoCD`  `Harbor`  `Velero`  `Minio`_

<br/>

**쿠버네티스 클러스터 재구축 및 마이그레이션 [2021.11 ~ 2022.02]**

- Control Plane 노드 3대와 HAProxy를 이용하여 고가용성 구성
- 개발용 클러스터 구축
- 클러스터별 접근제어 환경 구축 및 설정 (User Account, RBAC, OPA Gatekeeper)
- 사내 운영 서비스(Harbor, Minio, Grafana, Prometheus, Loki) 배포
- HCI VM과 Subnet을 관리할 수 있는 Terraform 모듈 작성

_Github. [https://github.com/Jivvon/nutanix-terraform-modules](https://github.com/Jivvon/nutanix-terraform-modules)_

_Tech Skills. `Kubernetes` `Helm` `Shell` `Terraform`_
